# Importing necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve, confusion_matrix

# Load the datasets
bank_full = pd.read_csv('/main/bank-full.csv', sep=';')

# Display basic information about the dataset
print("Full Dataset Info:")
print(bank_full.info())

# Display the first few rows of each dataset
print("\nFirst Few Rows of Full Dataset:")
print(bank_full.head())

# Check basic statistics for numerical columns
print("Numerical Statistics:")
print(bank_full.describe())

# Check the distribution of the target variable (y)
print("\nTarget Variable Distribution:")
print(bank_full['y'].value_counts(normalize=True))

# Visualize the target variable distribution
plt.figure(figsize=(6, 4))
sns.countplot(x='y', data=bank_full, palette='viridis')
plt.title("Distribution of Target Variable ('y')")
plt.xlabel("Subscribed to Term Deposit")
plt.ylabel("Count")
plt.show()

# List of numerical columns
numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']

# Visualize distributions of numerical features
bank_full[numerical_columns].hist(figsize=(12, 10), bins=20, color='skyblue', edgecolor='black')
plt.suptitle("Distributions of Numerical Attributes", fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Correlation heatmap for numerical features
plt.figure(figsize=(10, 8))
correlation_matrix = bank_full[numerical_columns].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap of Numerical Features")
plt.show()

# List of categorical columns
categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']

# Visualize distributions of categorical features
for column in categorical_columns:
    plt.figure(figsize=(10, 6))
    sns.countplot(y=column, data=bank_full, order=bank_full[column].value_counts().index, palette='viridis')
    plt.title(f"Distribution of {column.capitalize()}")
    plt.xlabel("Count")
    plt.ylabel(column.capitalize())
    plt.show()

# Encode Categorical Variables
categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']
target_column = 'y'

# Use LabelEncoder for target variable and One-Hot Encoding for features
label_encoder = LabelEncoder()
bank_full[target_column] = label_encoder.fit_transform(bank_full[target_column])  # Encode target (yes: 1, no: 0)

# Apply One-Hot Encoding to categorical features
bank_full_encoded = pd.get_dummies(bank_full, columns=categorical_columns, drop_first=True)

# Normalize/Scale Numerical Attributes
numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']
scaler = StandardScaler()
bank_full_encoded[numerical_columns] = scaler.fit_transform(bank_full_encoded[numerical_columns])

# Train-Test Split
X = bank_full_encoded.drop(columns=[target_column])  # Features
y = bank_full_encoded[target_column]  # Target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # Stratified Sampling has been used

# Verify the shapes of the train and test datasets
print(f"Training Features Shape: {X_train.shape}")
print(f"Testing Features Shape: {X_test.shape}")
print(f"Training Target Distribution:\n{y_train.value_counts(normalize=True)}")
print(f"Testing Target Distribution:\n{y_test.value_counts(normalize=True)}")

# Train the Random Forest Classifier
rf_model = RandomForestClassifier(random_state=42, n_estimators=100)
rf_model.fit(X_train, y_train)

# Predict on Test Data
y_pred_rf = rf_model.predict(X_test)
y_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# Evaluate the Random Forest Model
print("Random Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf)}")
print(f"AUC-ROC: {roc_auc_score(y_test, y_proba_rf)}")

# Visualize Confusion Matrix for Random Forest
conf_matrix = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Plot ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_proba_rf)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f"AUC = {roc_auc_score(y_test, y_proba_rf):.2f}")
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.title("ROC Curve - Random Forest")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# Build the Neural Network Model
nn_model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')
])

nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the Neural Network Model
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = nn_model.fit(X_train, y_train, 
                       validation_data=(X_test, y_test), 
                       epochs=50, 
                       batch_size=32, 
                       callbacks=[early_stopping], 
                       verbose=1)

# Evaluate the Neural Network Model
nn_loss, nn_accuracy = nn_model.evaluate(X_test, y_test)
y_proba_nn = nn_model.predict(X_test).flatten()

print(f"Neural Network Accuracy: {nn_accuracy}")
print(f"Neural Network AUC-ROC: {roc_auc_score(y_test, y_proba_nn)}")

# Plot Training History
plt.figure(figsize=(8, 6))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Neural Network Training History")
plt.xlabel("Epochs")
plt.ylabel("Accuracy/Loss")
plt.legend()
plt.show()

# Plot ROC Curve
fpr_nn, tpr_nn, _ = roc_curve(y_test, y_proba_nn)
plt.figure(figsize=(8, 6))
plt.plot(fpr_nn, tpr_nn, color='green', label=f"AUC = {roc_auc_score(y_test, y_proba_nn):.2f}")
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.title("ROC Curve - Neural Network")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# Convert predicted probabilities to binary predictions (threshold = 0.5)
y_pred_nn = (y_proba_nn >= 0.5).astype(int)

# Confusion matrix for Neural Network
conf_matrix_nn = confusion_matrix(y_test, y_pred_nn)

# Display confusion matrix
print("Confusion Matrix - Neural Network:")
print(conf_matrix_nn)

# Visualize confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix_nn, annot=True, fmt="d", cmap="Blues", xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title("Confusion Matrix - Neural Network")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Classification Report
print("Neural Network Classification Report:")
print(classification_report(y_test, y_pred_nn))

